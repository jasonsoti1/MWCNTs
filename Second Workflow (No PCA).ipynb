{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Lirbraries and load the Dataset, Code names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length ave. (nm)</th>\n",
       "      <th>Diameter ave. (nm)</th>\n",
       "      <th>BET (m2/g)</th>\n",
       "      <th>Purity (%)</th>\n",
       "      <th>Zave (batch)</th>\n",
       "      <th>PdI (batch)</th>\n",
       "      <th>Zave (12.5 ug/ml)</th>\n",
       "      <th>PdI  (12.5 ug/ml)</th>\n",
       "      <th>Zave  (200 ug/ml)</th>\n",
       "      <th>PdI  (200 ug/ml)</th>\n",
       "      <th>...</th>\n",
       "      <th>COOH mmol/g</th>\n",
       "      <th>Endotoxins (EU/mg)</th>\n",
       "      <th>Diameter min. (nm)</th>\n",
       "      <th>Diameter max. (nm)</th>\n",
       "      <th>Type_COOH</th>\n",
       "      <th>Type_NH2</th>\n",
       "      <th>Type_OH</th>\n",
       "      <th>Type_PRISTINE</th>\n",
       "      <th>% Total Impurities</th>\n",
       "      <th>Genotoxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198214</td>\n",
       "      <td>0.559322</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.036390</td>\n",
       "      <td>0.349333</td>\n",
       "      <td>0.020378</td>\n",
       "      <td>0.234910</td>\n",
       "      <td>0.067882</td>\n",
       "      <td>0.306306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.332558</td>\n",
       "      <td>0.206494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.134906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.093822</td>\n",
       "      <td>0.283929</td>\n",
       "      <td>0.567797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066958</td>\n",
       "      <td>0.730667</td>\n",
       "      <td>0.132460</td>\n",
       "      <td>0.375204</td>\n",
       "      <td>0.054205</td>\n",
       "      <td>0.570571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405941</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.390698</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.521186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035861</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.014556</td>\n",
       "      <td>0.097879</td>\n",
       "      <td>0.031408</td>\n",
       "      <td>0.357357</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.394805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048716</td>\n",
       "      <td>0.796429</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034653</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.775325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.219889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156550</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.045124</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.425036</td>\n",
       "      <td>0.365416</td>\n",
       "      <td>0.241641</td>\n",
       "      <td>0.822823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044554</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.444186</td>\n",
       "      <td>0.419481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length ave. (nm)   Diameter ave. (nm)  BET (m2/g)  Purity (%)  \\\n",
       "0           0.000000            0.198214    0.559322    0.934783   \n",
       "1           0.093822            0.283929    0.567797    1.000000   \n",
       "2           0.039432            0.342857    0.521186    1.000000   \n",
       "3           0.048716            0.796429    0.271186    0.923913   \n",
       "4           0.156550            0.387500    0.237288    0.934783   \n",
       "\n",
       "   Zave (batch)  PdI (batch)  Zave (12.5 ug/ml)  PdI  (12.5 ug/ml)  \\\n",
       "0      0.036390     0.349333           0.020378           0.234910   \n",
       "1      0.066958     0.730667           0.132460           0.375204   \n",
       "2      0.035861     0.413333           0.014556           0.097879   \n",
       "3      0.011777     0.026667           0.000000           0.000000   \n",
       "4      0.045124     0.024000           0.425036           0.365416   \n",
       "\n",
       "   Zave  (200 ug/ml)  PdI  (200 ug/ml)  ...  COOH mmol/g  Endotoxins (EU/mg)  \\\n",
       "0           0.067882          0.306306  ...     0.079208                0.34   \n",
       "1           0.054205          0.570571  ...     0.405941                0.42   \n",
       "2           0.031408          0.357357  ...     1.000000                0.50   \n",
       "3           0.013171          0.000000  ...     0.034653                0.48   \n",
       "4           0.241641          0.822823  ...     0.044554                0.52   \n",
       "\n",
       "   Diameter min. (nm)  Diameter max. (nm)  Type_COOH  Type_NH2  Type_OH  \\\n",
       "0            0.332558            0.206494          0         0        0   \n",
       "1            0.390698            0.298701          0         0        1   \n",
       "2            0.372093            0.394805          1         0        0   \n",
       "3            0.872093            0.775325          0         0        0   \n",
       "4            0.444186            0.419481          0         0        1   \n",
       "\n",
       "   Type_PRISTINE  % Total Impurities  Genotoxicity  \n",
       "0              1            0.134906             0  \n",
       "1              0            0.075646             0  \n",
       "2              0            0.048780             0  \n",
       "3              1            0.219889             0  \n",
       "4              0            0.190736             1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('pre-precessed_dataset.csv')\n",
    "codes = open('codes.txt','r').readlines()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Kennard_Stone import kennardstonealgorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Kennart-Stone algorithm, we split the dataset into 2 sets, one for training and one for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_labels, test_labels = kennardstonealgorithm(df,'Genotoxicity',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (10, 23)\n",
      "Training Labels Shape: (10,)\n",
      "Testing Features Shape: (5, 23)\n",
      "Testing Labels Shape: (5,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The names of the testing samples are:\n",
      "=====================================\n",
      "NRCWE- 040\n",
      "NRCWE- 041\n",
      "NRCWE- 048\n",
      "NM-401\n",
      "NM-402\n"
     ]
    }
   ],
   "source": [
    "print('The names of the testing samples are:')\n",
    "print('=====================================')\n",
    "for i in test.index:\n",
    "    print(codes[i][:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Bayesian Optimization Tool and Search for the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bayesian_Optimization import BayesOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo = BayesOpt(train, train_labels, folds=4, log_scaling=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization for the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for linear kernel\n",
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.625   \u001b[0m | \u001b[0m 4.371   \u001b[0m | \u001b[0m 0.9556  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.625   \u001b[0m | \u001b[0m 7.588   \u001b[0m | \u001b[0m 0.6388  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.625   \u001b[0m | \u001b[0m 2.404   \u001b[0m | \u001b[0m 0.2404  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.625   \u001b[0m | \u001b[0m 1.523   \u001b[0m | \u001b[0m 0.8796  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.625   \u001b[0m | \u001b[0m 6.41    \u001b[0m | \u001b[0m 0.7373  \u001b[0m |\n",
      "Error related to scaling.\n",
      "Optimizing for poly kernel\n",
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 4.371   \u001b[0m | \u001b[0m 0.9556  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 7.588   \u001b[0m | \u001b[0m 0.6388  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 2.404   \u001b[0m | \u001b[0m 0.2404  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 1.523   \u001b[0m | \u001b[0m 0.8796  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 6.41    \u001b[0m | \u001b[0m 0.7373  \u001b[0m |\n",
      "Error related to scaling.\n",
      "Optimizing for rbf kernel\n",
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.4167  \u001b[0m | \u001b[0m 4.371   \u001b[0m | \u001b[0m 0.9556  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 7.588   \u001b[0m | \u001b[0m 0.6388  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 2.404   \u001b[0m | \u001b[0m 0.2404  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.4167  \u001b[0m | \u001b[0m 1.523   \u001b[0m | \u001b[0m 0.8796  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 6.41    \u001b[0m | \u001b[0m 0.7373  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.4167  \u001b[0m | \u001b[0m 1.576   \u001b[0m | \u001b[0m 0.8423  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 4.543   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.2917  \u001b[0m | \u001b[0m 3.788   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.2917  \u001b[0m | \u001b[0m 4.68    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.4167  \u001b[0m | \u001b[0m 4.267   \u001b[0m | \u001b[0m 0.8153  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 1.412   \u001b[0m | \u001b[0m 0.6645  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.4167  \u001b[0m | \u001b[0m 4.976   \u001b[0m | \u001b[0m 0.8419  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.4167  \u001b[0m | \u001b[0m 4.189   \u001b[0m | \u001b[0m 0.9754  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.2917  \u001b[0m | \u001b[0m 1.665   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.4167  \u001b[0m | \u001b[0m 4.411   \u001b[0m | \u001b[0m 0.8173  \u001b[0m |\n",
      "=================================================\n",
      "Optimizing for sigmoid kernel\n",
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5417  \u001b[0m | \u001b[0m 4.371   \u001b[0m | \u001b[0m 0.9556  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 7.588   \u001b[0m | \u001b[0m 0.6388  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.4167  \u001b[0m | \u001b[0m 2.404   \u001b[0m | \u001b[0m 0.2404  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5417  \u001b[0m | \u001b[0m 1.523   \u001b[0m | \u001b[0m 0.8796  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5417  \u001b[0m | \u001b[0m 6.41    \u001b[0m | \u001b[0m 0.7373  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5417  \u001b[0m | \u001b[0m 4.393   \u001b[0m | \u001b[0m 0.9297  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5417  \u001b[0m | \u001b[0m 5.544   \u001b[0m | \u001b[0m 0.9556  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 5.711   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5417  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5402  \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.625   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.1     \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.6859  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5417  \u001b[0m | \u001b[0m 9.758   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.7083  \u001b[0m | \u001b[95m 9.98    \u001b[0m | \u001b[95m 0.2536  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.625   \u001b[0m | \u001b[0m 9.894   \u001b[0m | \u001b[0m 0.3342  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.625   \u001b[0m | \u001b[0m 9.996   \u001b[0m | \u001b[0m 0.307   \u001b[0m |\n",
      "=================================================\n",
      "\n",
      "\n",
      "Final result: The optimal model's accuracy is 0.7083333333333333 and the optimal parameters are C=9.980336922752942, gamma=0.2535670354897066 and kernel=sigmoid\n"
     ]
    }
   ],
   "source": [
    "# Get the time that the optimization started\n",
    "start_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "# # Boundaries of the hyperparameters\n",
    "params = {'C': (1,10), 'gamma':(0.1,1)}\n",
    "\n",
    "# Optimization\n",
    "svm_optimum = bo.optimize_svm(params)\n",
    "\n",
    "# Get the time that the optimization ended\n",
    "end_time = datetime.now().strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes to execute: 0.02\n"
     ]
    }
   ],
   "source": [
    "print('Minutes to execute:', \n",
    "      round((datetime.strptime(end_time, '%H:%M:%S') - datetime.strptime(start_time, '%H:%M:%S')).seconds/60,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization for the RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.6498  \u001b[0m | \u001b[0m 0.8606  \u001b[0m | \u001b[0m 7.588   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.375   \u001b[0m | \u001b[0m 0.7395  \u001b[0m | \u001b[0m 0.2248  \u001b[0m | \u001b[0m 2.404   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.5833  \u001b[0m | \u001b[95m 0.5232  \u001b[0m | \u001b[95m 0.7929  \u001b[0m | \u001b[95m 6.41    \u001b[0m |\n",
      "| \u001b[0m 4      \u001b[0m | \u001b[0m 0.9167  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.375   \u001b[0m | \u001b[0m 0.833   \u001b[0m | \u001b[0m 0.2699  \u001b[0m | \u001b[0m 2.636   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.4167  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9167  \u001b[0m | \u001b[0m 0.8302  \u001b[0m | \u001b[0m 0.1147  \u001b[0m | \u001b[0m 9.733   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9167  \u001b[0m | \u001b[0m 0.87    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 9.067   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.375   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 4.876   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8333  \u001b[0m | \u001b[0m 0.52    \u001b[0m | \u001b[0m 0.1188  \u001b[0m | \u001b[0m 8.577   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9167  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 9.243   \u001b[0m |\n",
      "| \u001b[95m 13       \u001b[0m | \u001b[95m 0.9167  \u001b[0m | \u001b[95m 0.7832  \u001b[0m | \u001b[95m 0.1165  \u001b[0m | \u001b[95m 9.729   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9167  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 9.631   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9167  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "=============================================================\n",
      "\n",
      "\n",
      "Final result: The optimal model's score is 0.9166666666666666 and the optimal parameters are n_estimators=10, min_samples_split=0.1 and max_features=0.5\n"
     ]
    }
   ],
   "source": [
    "# Get the time that the optimization started\n",
    "start_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Boundaries of the hyperparameters\n",
    "params={\"n_estimators\": (1,10), \"min_samples_split\": (0.1,0.9), \"max_features\": (0.5, 0.9)}\n",
    "\n",
    "# Optimization\n",
    "rf_optimum = bo.optimize_rf(params)\n",
    "\n",
    "# Get the time that the optimization ended\n",
    "end_time = datetime.now().strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes to execute: 0.03\n"
     ]
    }
   ],
   "source": [
    "print('Minutes to execute:', \n",
    "      round((datetime.strptime(end_time, '%H:%M:%S') - datetime.strptime(start_time, '%H:%M:%S')).seconds/60,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization for the LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for l1 penalty\n",
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 43.71   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 95.56   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 75.88   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 63.88   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 24.04   \u001b[0m |\n",
      "Error related to scaling.\n",
      "Optimizing for l2 penalty\n",
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 43.71   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 95.56   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 75.88   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 63.88   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 24.04   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 53.29   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 45.57   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 86.13   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 69.92   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 58.45   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 81.21   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 90.92   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 66.91   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 49.91   \u001b[0m |\n",
      "=====================================\n",
      "\n",
      "\n",
      "Final result: The optimal model's accuracy is 0.4583333333333333 and the optimal parameters are C=43.708610696262625 and penalty=l2\n"
     ]
    }
   ],
   "source": [
    "# Get the time that the optimization started\n",
    "start_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Boundaries of the hyperparameters\n",
    "params={'C' : (10,100)}\n",
    "\n",
    "# Optimization\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "lr_optimum = bo.optimize_lr(params)\n",
    "\n",
    "# Get the time that the optimization ended\n",
    "end_time = datetime.now().strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes to execute: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Minutes to execute:', \n",
    "      round((datetime.strptime(end_time, '%H:%M:%S') - datetime.strptime(start_time, '%H:%M:%S')).seconds/60,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the models and Test the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import (accuracy_score,matthews_corrcoef,\n",
    "                             classification_report, confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the model\n",
    "svc = SVC(C=svm_optimum['params']['C'], gamma=svm_optimum['params']['gamma'], kernel=svm_optimum['params']['kernel'], random_state=42)\n",
    "\n",
    "# Train the model on training data\n",
    "svc.fit(train, train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method \n",
    "predictions = svc.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM's training accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Print the Training accuracy\n",
    "print(\"SVM's training accuracy:\", accuracy_score(train_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.92      0.90      0.90        10\n",
      "weighted avg       0.92      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "4 | 1\n",
      "-----\n",
      "0 | 5\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(train_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.8\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(train_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.816496580927726\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of scores: [0.66666667 0.66666667 1.         0.5       ]\n",
      "Mean of Cross Validtation: 0.7083333333333333\n"
     ]
    }
   ],
   "source": [
    "#Print the Cross-Validation Score\n",
    "scores = cross_val_score(svc, train, train_labels, cv=4)\n",
    "\n",
    "print('List of scores:', scores)\n",
    "print('Mean of Cross Validtation:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method\n",
    "predictions = svc.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM's testing accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Print the Testing accuracy\n",
    "print(\"SVM's testing accuracy:\", accuracy_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.75      0.88      0.76         5\n",
      "weighted avg       0.90      0.80      0.82         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "3 | 1\n",
      "-----\n",
      "0 | 1\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.75\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.6123724356957946\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the model\n",
    "clf = RandomForestClassifier(n_estimators=rf_optimum['params']['n_estimators'], max_features=rf_optimum['params']['max_features'], min_samples_split=rf_optimum['params']['min_samples_split'],  random_state=42)\n",
    "\n",
    "# Train the model on training data\n",
    "clf.fit(train, train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method\n",
    "predictions = clf.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF's training accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the Train accuracy\n",
    "print(\"RF's training accuracy:\", accuracy_score(train_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "5 | 0\n",
      "-----\n",
      "0 | 5\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(train_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 1.0\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(train_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of scores: [1.         0.66666667 1.         1.        ]\n",
      "Mean of Cross Validtation: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "#Print the Cross-Validation Score\n",
    "scores = cross_val_score(clf, train, train_labels, cv=4)\n",
    "\n",
    "print('List of scores:', scores)\n",
    "print('Mean of Cross Validtation:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method\n",
    "predictions = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF's testing accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Print the Test accuracy\n",
    "print(\"RF's testing accuracy:\", accuracy_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.67      0.75      0.58         5\n",
      "weighted avg       0.87      0.60      0.63         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "2 | 2\n",
      "-----\n",
      "0 | 1\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.5\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.4082482904638631\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the model\n",
    "logmodel = LogisticRegression(C=lr_optimum['params']['C'], penalty=lr_optimum['params']['penalty'],random_state=42)\n",
    "\n",
    "# Train the model on training data\n",
    "logmodel.fit(train, train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method\n",
    "predictions = logmodel.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR's training accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the train accuracy\n",
    "print(\"LR's training accuracy:\", accuracy_score(train_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "5 | 0\n",
      "-----\n",
      "0 | 5\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(train_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 1.0\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(train_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of scores: [0.         0.33333333 1.         0.5       ]\n",
      "Mean of Cross Validtation: 0.4583333333333333\n"
     ]
    }
   ],
   "source": [
    "#Print the Cross-Validation Score\n",
    "scores = cross_val_score(logmodel, train, train_labels, cv=4)\n",
    "\n",
    "print('List of scores:', scores)\n",
    "print('Mean of Cross Validtation:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method\n",
    "predictions = logmodel.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR's testing accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Print the Test accuracy\n",
    "print(\"LR's testing accuracy:\", accuracy_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.75      0.88      0.76         5\n",
      "weighted avg       0.90      0.80      0.82         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "3 | 1\n",
      "-----\n",
      "0 | 1\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.75\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.6123724356957946\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model on training data\n",
    "gnb.fit(train,train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method\n",
    "predictions = gnb.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB's accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the train accuracy\n",
    "print(\"NB's accuracy:\", accuracy_score(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "5 | 0\n",
      "-----\n",
      "0 | 5\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(train_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 1.0\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(train_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of scores: [0.         0.33333333 0.5        1.        ]\n",
      "Mean of Cross Validtation: 0.4583333333333333\n"
     ]
    }
   ],
   "source": [
    "#Print the Cross-Validation Score\n",
    "scores = cross_val_score(gnb, train, train_labels, cv=4)\n",
    "\n",
    "print('List of scores:', scores)\n",
    "print('Mean of Cross Validtation:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method on the test data\n",
    "predictions = gnb.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB's accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Print the Test accuracy\n",
    "print(\"NB's accuracy:\", accuracy_score(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.67      0.75      0.58         5\n",
      "weighted avg       0.87      0.60      0.63         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "2 | 2\n",
      "-----\n",
      "0 | 1\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.5\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.4082482904638631\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models for the RFE method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, 'RF_model.sav');\n",
    "joblib.dump(logmodel, 'LR_model.sav');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Lirbraries and load the Dataset, Code names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length ave. (nm)</th>\n",
       "      <th>Diameter ave. (nm)</th>\n",
       "      <th>BET (m2/g)</th>\n",
       "      <th>Purity (%)</th>\n",
       "      <th>Zave (batch)</th>\n",
       "      <th>PdI (batch)</th>\n",
       "      <th>Zave (12.5 ug/ml)</th>\n",
       "      <th>PdI  (12.5 ug/ml)</th>\n",
       "      <th>Zave  (200 ug/ml)</th>\n",
       "      <th>PdI  (200 ug/ml)</th>\n",
       "      <th>...</th>\n",
       "      <th>COOH mmol/g</th>\n",
       "      <th>Endotoxins (EU/mg)</th>\n",
       "      <th>Diameter min. (nm)</th>\n",
       "      <th>Diameter max. (nm)</th>\n",
       "      <th>Type_COOH</th>\n",
       "      <th>Type_NH2</th>\n",
       "      <th>Type_OH</th>\n",
       "      <th>Type_PRISTINE</th>\n",
       "      <th>% Total Impurities</th>\n",
       "      <th>Genotoxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198214</td>\n",
       "      <td>0.559322</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.036390</td>\n",
       "      <td>0.349333</td>\n",
       "      <td>0.020378</td>\n",
       "      <td>0.234910</td>\n",
       "      <td>0.067882</td>\n",
       "      <td>0.306306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.332558</td>\n",
       "      <td>0.206494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.134906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.093822</td>\n",
       "      <td>0.283929</td>\n",
       "      <td>0.567797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066958</td>\n",
       "      <td>0.730667</td>\n",
       "      <td>0.132460</td>\n",
       "      <td>0.375204</td>\n",
       "      <td>0.054205</td>\n",
       "      <td>0.570571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405941</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.390698</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.521186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035861</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.014556</td>\n",
       "      <td>0.097879</td>\n",
       "      <td>0.031408</td>\n",
       "      <td>0.357357</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.394805</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048716</td>\n",
       "      <td>0.796429</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034653</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.775325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.219889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156550</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.045124</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.425036</td>\n",
       "      <td>0.365416</td>\n",
       "      <td>0.241641</td>\n",
       "      <td>0.822823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044554</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.444186</td>\n",
       "      <td>0.419481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length ave. (nm)   Diameter ave. (nm)  BET (m2/g)  Purity (%)  \\\n",
       "0           0.000000            0.198214    0.559322    0.934783   \n",
       "1           0.093822            0.283929    0.567797    1.000000   \n",
       "2           0.039432            0.342857    0.521186    1.000000   \n",
       "3           0.048716            0.796429    0.271186    0.923913   \n",
       "4           0.156550            0.387500    0.237288    0.934783   \n",
       "\n",
       "   Zave (batch)  PdI (batch)  Zave (12.5 ug/ml)  PdI  (12.5 ug/ml)  \\\n",
       "0      0.036390     0.349333           0.020378           0.234910   \n",
       "1      0.066958     0.730667           0.132460           0.375204   \n",
       "2      0.035861     0.413333           0.014556           0.097879   \n",
       "3      0.011777     0.026667           0.000000           0.000000   \n",
       "4      0.045124     0.024000           0.425036           0.365416   \n",
       "\n",
       "   Zave  (200 ug/ml)  PdI  (200 ug/ml)  ...  COOH mmol/g  Endotoxins (EU/mg)  \\\n",
       "0           0.067882          0.306306  ...     0.079208                0.34   \n",
       "1           0.054205          0.570571  ...     0.405941                0.42   \n",
       "2           0.031408          0.357357  ...     1.000000                0.50   \n",
       "3           0.013171          0.000000  ...     0.034653                0.48   \n",
       "4           0.241641          0.822823  ...     0.044554                0.52   \n",
       "\n",
       "   Diameter min. (nm)  Diameter max. (nm)  Type_COOH  Type_NH2  Type_OH  \\\n",
       "0            0.332558            0.206494        0.0       0.0      0.0   \n",
       "1            0.390698            0.298701        0.0       0.0      1.0   \n",
       "2            0.372093            0.394805        1.0       0.0      0.0   \n",
       "3            0.872093            0.775325        0.0       0.0      0.0   \n",
       "4            0.444186            0.419481        0.0       0.0      1.0   \n",
       "\n",
       "   Type_PRISTINE  % Total Impurities  Genotoxicity  \n",
       "0            1.0            0.134906             0  \n",
       "1            0.0            0.075646             0  \n",
       "2            0.0            0.048780             0  \n",
       "3            1.0            0.219889             0  \n",
       "4            0.0            0.190736             1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('pre-precessed_dataset.csv')\n",
    "codes = open('codes.txt','r').readlines()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Kennard_Stone import kennardstonealgorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Kennart-Stone algorithm, we split the dataset into 2 sets, one for training and one for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_labels, test_labels = kennardstonealgorithm(df,'Genotoxicity',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (10, 34)\n",
      "Training Labels Shape: (10,)\n",
      "Testing Features Shape: (5, 34)\n",
      "Testing Labels Shape: (5,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The names of the testing samples are:\n",
      "=====================================\n",
      "NRCWE- 040\n",
      "NRCWE- 045\n",
      "NRCWE- 048\n",
      "NM-401\n",
      "NM-402\n"
     ]
    }
   ],
   "source": [
    "print('The names of the testing samples are:')\n",
    "print('=====================================')\n",
    "for i in test.index:\n",
    "    print(codes[i][:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain of Applicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "np_train_labels = np.array(train_labels)\n",
    "np_test_labels = np.array(test_labels)\n",
    "np_test = np.array(test)\n",
    "np_train = np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Leverage threshold is: 10.2\n"
     ]
    }
   ],
   "source": [
    "leverage_threshold = 3*np_train.shape[1]/np_train.shape[0]\n",
    "print('The Leverage threshold is:', round(leverage_threshold, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: NRCWE- 040    Leverage Value: -121732331865742.0    Reliability: reliable\n",
      "Sample: NRCWE- 041    Leverage Value: -5645595156943288.0    Reliability: reliable\n",
      "Sample: NRCWE- 042    Leverage Value: -5257845161379162.0    Reliability: reliable\n",
      "Sample: NRCWE- 043    Leverage Value: -1904003326267884.2    Reliability: reliable\n",
      "Sample: NRCWE- 044    Leverage Value: 1379342182684633.5    Reliability: unreliable\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import matrix_power\n",
    "H=[]\n",
    "reliability=[]\n",
    "for i in range(len(np_test)):\n",
    "    H.append(np_test[i].T@(matrix_power(np_train.T@np_train, -1))@np_test[i])\n",
    "    if H[i]<=leverage_threshold:\n",
    "        reliability.append('reliable')\n",
    "    else:\n",
    "        reliability.append('unreliable')\n",
    "\n",
    "LV = [(sample[:-1], round(l_val, 2),rely) for sample, l_val, rely in zip(codes, H, reliability)]\n",
    "for i in range(len(np_test)):\n",
    "    [print('Sample: {:13} Leverage Value: {}    Reliability: {}'.format(LV[i][0],LV[i][1],LV[i][2]))];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Bayesian Optimization Tool and Search for the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bayesian_Optimization import optimize_svm, optimize_rfc, optimize_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization for the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for linear kernel\n",
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 499.6   \u001b[0m | \u001b[0m 0.9556  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 785.6   \u001b[0m | \u001b[0m 0.6388  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 324.8   \u001b[0m | \u001b[0m 0.2404  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 1e+03   \u001b[0m | \u001b[0m 0.45    \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 0.2804  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 1e+03   \u001b[0m | \u001b[0m 0.2242  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 200.1   \u001b[0m | \u001b[0m 0.8236  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 1e+03   \u001b[0m | \u001b[0m 0.96    \u001b[0m |\n",
      "=================================================\n",
      "Optimizing for poly kernel\n",
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 499.6   \u001b[0m | \u001b[0m 0.9556  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 785.6   \u001b[0m | \u001b[0m 0.6388  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 324.8   \u001b[0m | \u001b[0m 0.2404  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 1e+03   \u001b[0m | \u001b[0m 0.45    \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 0.2804  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 1e+03   \u001b[0m | \u001b[0m 0.2242  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 200.1   \u001b[0m | \u001b[0m 0.8236  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 1e+03   \u001b[0m | \u001b[0m 0.96    \u001b[0m |\n",
      "=================================================\n",
      "Optimizing for rbf kernel\n",
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 40.0    \u001b[0m | \u001b[0m 499.6   \u001b[0m | \u001b[0m 0.9556  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 60.0    \u001b[0m | \u001b[95m 785.6   \u001b[0m | \u001b[95m 0.6388  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 324.8   \u001b[0m | \u001b[0m 0.2404  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 325.1   \u001b[0m | \u001b[0m 0.2425  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 800.3   \u001b[0m | \u001b[0m 0.617   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 80.0    \u001b[0m | \u001b[95m 792.9   \u001b[0m | \u001b[95m 0.1     \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 792.9   \u001b[0m | \u001b[0m 0.3169  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 345.0   \u001b[0m | \u001b[0m 0.326   \u001b[0m |\n",
      "=================================================\n",
      "Optimizing for sigmoid kernel\n",
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 499.6   \u001b[0m | \u001b[0m 0.9556  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 40.0    \u001b[0m | \u001b[0m 785.6   \u001b[0m | \u001b[0m 0.6388  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 324.8   \u001b[0m | \u001b[0m 0.2404  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 499.5   \u001b[0m | \u001b[0m 0.9486  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 80.0    \u001b[0m | \u001b[95m 500.1   \u001b[0m | \u001b[95m 0.1     \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 40.0    \u001b[0m | \u001b[0m 500.1   \u001b[0m | \u001b[0m 0.1959  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 500.1   \u001b[0m | \u001b[0m 0.1086  \u001b[0m |\n",
      "=================================================\n",
      "\n",
      "\n",
      "Final result: The optimal model's accuracy is 80.0 and the optimal parameters are C=499.63209507788997, gamma=0.9556428757689246 and kernel=linear\n"
     ]
    }
   ],
   "source": [
    "# Get the time that the optimization started\n",
    "start_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Boundaries of the hyperparameters\n",
    "bo_dict={'C':(200,1000) , 'gamma' : (0.1,1)}\n",
    "\n",
    "# Optimization\n",
    "svm_optimum = optimize_svm(train,train_labels,test,test_labels,bo_dict,5,3)\n",
    "\n",
    "# Get the time that the optimization ended\n",
    "end_time = datetime.now().strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes to execute: 0.83\n"
     ]
    }
   ],
   "source": [
    "print('Minutes to execute:', \n",
    "      round((datetime.strptime(end_time, '%H:%M:%S') - datetime.strptime(start_time, '%H:%M:%S')).seconds/60,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization for the RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.3996  \u001b[0m | \u001b[0m 0.4803  \u001b[0m | \u001b[0m 185.7   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.5789  \u001b[0m | \u001b[0m 0.1624  \u001b[0m | \u001b[0m 47.44   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.1465  \u001b[0m | \u001b[0m 0.4465  \u001b[0m | \u001b[0m 154.3   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.6665  \u001b[0m | \u001b[0m 0.1082  \u001b[0m | \u001b[0m 242.8   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 0.1849  \u001b[0m | \u001b[0m 53.64   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 50.57   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.5279  \u001b[0m | \u001b[0m 0.2735  \u001b[0m | \u001b[0m 83.06   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.2148  \u001b[0m | \u001b[0m 0.1272  \u001b[0m | \u001b[0m 206.8   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.1261  \u001b[0m | \u001b[0m 0.1903  \u001b[0m | \u001b[0m 240.5   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.8246  \u001b[0m | \u001b[0m 0.2802  \u001b[0m | \u001b[0m 188.7   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.2763  \u001b[0m | \u001b[0m 0.1292  \u001b[0m | \u001b[0m 23.38   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.424   \u001b[0m | \u001b[0m 0.1757  \u001b[0m | \u001b[0m 102.3   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.2451  \u001b[0m | \u001b[0m 0.2517  \u001b[0m | \u001b[0m 57.61   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.1287  \u001b[0m | \u001b[0m 0.4528  \u001b[0m | \u001b[0m 179.6   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.8021  \u001b[0m | \u001b[0m 0.3189  \u001b[0m | \u001b[0m 59.7    \u001b[0m |\n",
      "=============================================================\n",
      "\n",
      "\n",
      "Final result: The optimal model's accuracy is 80.0 and the optimal parameters are n_estimators=185, min_samples_split=0.4802857225639665 and max_features=0.39963209507789\n"
     ]
    }
   ],
   "source": [
    "# Get the time that the optimization started\n",
    "start_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Boundaries of the hyperparameters\n",
    "bo_dict={\"n_estimators\": (10,250), \"min_samples_split\": (0.1,0.5), \"max_features\": (0.1, 0.9)}\n",
    "\n",
    "# Optimization\n",
    "rf_optimum = optimize_rfc(train,train_labels,test,test_labels,bo_dict,10,5)\n",
    "\n",
    "# Get the time that the optimization ended\n",
    "end_time = datetime.now().strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes to execute: 0.13\n"
     ]
    }
   ],
   "source": [
    "print('Minutes to execute:', \n",
    "      round((datetime.strptime(end_time, '%H:%M:%S') - datetime.strptime(start_time, '%H:%M:%S')).seconds/60,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization for the LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for l1 norm\n",
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 43.71   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 95.56   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 75.88   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 85.98   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 50.13   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 65.74   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 58.52   \u001b[0m |\n",
      "=====================================\n",
      "Optimizing for l2 norm\n",
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 43.71   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 95.56   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 75.88   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 99.99   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 10.02   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 99.99   \u001b[0m |\n",
      "=====================================\n",
      "\n",
      "\n",
      "Final result: The optimal model's accuracy is 80.0 and the optimal parameters are C=43.708610696262625 and penalty=l1\n"
     ]
    }
   ],
   "source": [
    "# Get the time that the optimization started\n",
    "start_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Boundaries of the hyperparameters\n",
    "bo_dict={'C' : (10,100)}\n",
    "\n",
    "# Optimization\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "lr_optimum = optimize_lr(train,train_labels,test,test_labels,bo_dict,5,3)\n",
    "\n",
    "# Get the time that the optimization ended\n",
    "end_time = datetime.now().strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes to execute: 0.33\n"
     ]
    }
   ],
   "source": [
    "print('Minutes to execute:', \n",
    "      round((datetime.strptime(end_time, '%H:%M:%S') - datetime.strptime(start_time, '%H:%M:%S')).seconds/60,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the models and Test the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import (accuracy_score,matthews_corrcoef,\n",
    "                             classification_report, confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the model\n",
    "svc = SVC(C=svm_optimum['params']['C'], gamma=svm_optimum['params']['gamma'], kernel=svm_optimum['params']['kernel'], random_state=42)\n",
    "\n",
    "# Train the model on training data\n",
    "svc.fit(train, train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method \n",
    "predictions = svc.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM's training accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the Training accuracy\n",
    "print(\"SVM's training accuracy:\", accuracy_score(train_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "6 | 0\n",
      "-----\n",
      "0 | 4\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(train_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 1.0\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(train_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of scores: [0.66666667 0.66666667 0.5        0.5       ]\n",
      "Mean of Cross Validtation: 0.5833333333333333\n"
     ]
    }
   ],
   "source": [
    "#Print the Cross-Validation Score\n",
    "scores = cross_val_score(svc, train, train_labels, cv=4)\n",
    "\n",
    "print('List of scores:', scores)\n",
    "print('Mean of Cross Validtation:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method\n",
    "predictions = svc.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM's testing accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Print the Testing accuracy\n",
    "print(\"SVM's testing accuracy:\", accuracy_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "   micro avg       0.80      0.80      0.80         5\n",
      "   macro avg       0.83      0.83      0.80         5\n",
      "weighted avg       0.87      0.80      0.80         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "2 | 1\n",
      "-----\n",
      "0 | 2\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.6666666666666666\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the model\n",
    "clf = RandomForestClassifier(n_estimators=rf_optimum['params']['n_estimators'], max_features=rf_optimum['params']['max_features'], min_samples_split=rf_optimum['params']['min_samples_split'],  random_state=42)\n",
    "\n",
    "# Train the model on training data\n",
    "clf.fit(train, train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method\n",
    "predictions = clf.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF's training accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the Train accuracy\n",
    "print(\"RF's training accuracy:\", accuracy_score(train_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "6 | 0\n",
      "-----\n",
      "0 | 4\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(train_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 1.0\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(train_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of scores: [0.66666667 0.33333333 0.5        0.5       ]\n",
      "Mean of Cross Validtation: 0.5\n"
     ]
    }
   ],
   "source": [
    "#Print the Cross-Validation Score\n",
    "scores = cross_val_score(clf, train, train_labels, cv=4)\n",
    "\n",
    "print('List of scores:', scores)\n",
    "print('Mean of Cross Validtation:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method\n",
    "predictions = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF's testing accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Print the Test accuracy\n",
    "print(\"RF's testing accuracy:\", accuracy_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "   micro avg       0.80      0.80      0.80         5\n",
      "   macro avg       0.83      0.83      0.80         5\n",
      "weighted avg       0.87      0.80      0.80         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "2 | 1\n",
      "-----\n",
      "0 | 2\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.6666666666666666\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the model\n",
    "logmodel = LogisticRegression(C=lr_optimum['params']['C'], penalty=lr_optimum['params']['norm'],random_state=42)\n",
    "\n",
    "# Train the model on training data\n",
    "logmodel.fit(train, train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method\n",
    "predictions = logmodel.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR's training accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the train accuracy\n",
    "print(\"LR's training accuracy:\", accuracy_score(train_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "6 | 0\n",
      "-----\n",
      "0 | 4\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(train_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 1.0\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(train_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of scores: [0.66666667 0.33333333 1.         0.5       ]\n",
      "Mean of Cross Validtation: 0.625\n"
     ]
    }
   ],
   "source": [
    "#Print the Cross-Validation Score\n",
    "scores = cross_val_score(logmodel, train, train_labels, cv=4)\n",
    "\n",
    "print('List of scores:', scores)\n",
    "print('Mean of Cross Validtation:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method\n",
    "predictions = logmodel.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR's testing accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Print the Test accuracy\n",
    "print(\"LR's testing accuracy:\", accuracy_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "   micro avg       0.80      0.80      0.80         5\n",
      "   macro avg       0.83      0.83      0.80         5\n",
      "weighted avg       0.87      0.80      0.80         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "2 | 1\n",
      "-----\n",
      "0 | 2\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.6666666666666666\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model on training data\n",
    "gnb.fit(train,train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method\n",
    "predictions = gnb.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB's accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Print the train accuracy\n",
    "print(\"NB's accuracy:\", accuracy_score(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       0.67      1.00      0.80         4\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        10\n",
      "   macro avg       0.83      0.83      0.80        10\n",
      "weighted avg       0.87      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "4 | 2\n",
      "-----\n",
      "0 | 4\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(train_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.6666666666666666\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(train_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(train_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of scores: [0.66666667 0.33333333 0.5        1.        ]\n",
      "Mean of Cross Validtation: 0.625\n"
     ]
    }
   ],
   "source": [
    "#Print the Cross-Validation Score\n",
    "scores = cross_val_score(gnb, train, train_labels, cv=4)\n",
    "\n",
    "print('List of scores:', scores)\n",
    "print('Mean of Cross Validtation:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics on the Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model's predict method on the test data\n",
    "predictions = gnb.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB's accuracy: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Print the Test accuracy\n",
    "print(\"NB's accuracy:\", accuracy_score(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "   micro avg       0.40      0.40      0.40         5\n",
      "   macro avg       0.42      0.42      0.40         5\n",
      "weighted avg       0.43      0.40      0.40         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "1 | 2\n",
      "-----\n",
      "1 | 1\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels,predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(cm[0][0],'|',cm[0][1])\n",
    "print('-----')\n",
    "print(cm[1][0],'|',cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.3333333333333333\n",
      "Sensitivity: 0.5\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_labels,predictions).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Specificity:',specificity)\n",
    "print('Sensitivity:',sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: -0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Print the MCC\n",
    "print('MCC:', matthews_corrcoef(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models for the RFE method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, 'RF_model.sav');\n",
    "joblib.dump(logmodel, 'LR_model.sav');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
